{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3021ed0b-4a8f-4e20-8c8f-37c931a5719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 612 titles and views to 'Test Scrapping V2.csv'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def get_youtube_shorts_titles_and_views(url):\n",
    "    # Set up the Selenium webdriver\n",
    "    driver = webdriver.Chrome()  # Ensure the correct ChromeDriver version is being used\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "\n",
    "    ## Use the code below to get titles and Views from Shorts instaed of Longform Videos\n",
    "\n",
    "    '''\n",
    "    # Click the \"Shorts\" tab using the correct XPath\n",
    "    try:\n",
    "        shorts_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//yt-formatted-string[@title='Shorts' and text()='Shorts']\"))\n",
    "        )\n",
    "        shorts_button.click()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        driver.quit()\n",
    "        return []   \n",
    "    '''   \n",
    "    \n",
    "    # Scroll down to load more videos\n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Wait to load the page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:  # If we've reached the bottom, stop scrolling\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Get the page source and parse it with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extract the shorts video titles and views\n",
    "    titles_and_views = []\n",
    "    for result in soup.find_all('a', id='video-title'):\n",
    "        title = result.text.strip()\n",
    "\n",
    "        # Extract the views from the next sibling span with the specified class\n",
    "        views_tag = result.find_next('span', class_='inline-metadata-item style-scope ytd-video-meta-block')\n",
    "        views = views_tag.text.strip() if views_tag else \"N/A\"  # If views are found, store them\n",
    "\n",
    "        titles_and_views.append((title, views))  # Append a tuple of (title, views)\n",
    "\n",
    "    # Close the webdriver\n",
    "    driver.quit()\n",
    "\n",
    "    return titles_and_views\n",
    "\n",
    "# Function to save titles and views to CSV\n",
    "def save_titles_and_views_to_csv(titles_and_views, filename):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['No.', 'Title', 'Views'])  # Write the header\n",
    "        for i, (title, views) in enumerate(titles_and_views[:10], start=1):  # Set the number of titles that you want to collect\n",
    "            writer.writerow([i, title, views])  # Write each title and views in the CSV\n",
    "\n",
    "# URL to scrape\n",
    "url = \"https://www.youtube.com/results?search_query=data+analysis+with+excel\" #Post your URL here to get the desired results\n",
    "titles_and_views = get_youtube_shorts_titles_and_views(url)\n",
    "\n",
    "# Save the titles and views to a CSV file\n",
    "csv_filename = 'Test Scrapping V2.csv' # Rename the file as you want\n",
    "save_titles_and_views_to_csv(titles_and_views, csv_filename)\n",
    "\n",
    "print(f\"Successfully saved {len(titles_and_views)} titles and views to '{csv_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32350a-1b18-4635-94f8-87b6ec2da719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
